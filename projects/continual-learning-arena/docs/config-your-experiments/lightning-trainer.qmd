---
title: Config Your Lightning Trainer
---

Under the framework of PyTorch Lightning, we use the Lightning Trainer for all the stuff in terms of training. Just like optimizer, t should have each trainer for each task in continual learning. We could apply one optimizer to all tasks or assign each task a specific trainer.

To configure the Lightning Trainer for your experiment, link the `trainer` field in the main YAML file to sub-config file of the directory [configs/trainer/] , and specify the class `Trainer` (only one class) and its arguments in the sub-config. Here is an example:

```
./clarena/example_configs
├── __init__.py
├── example.yaml
├── trainer
│   └── cpu.yaml
...
```

```{.yaml filename="example_configs/example.yaml"}
defaults:
  ...
  - trainer: cpu.yaml
  ...

```

```{.yaml filename="example_configs/trainer/cpu.yaml"}
_target_: lightning.Trainer

default_root_dir: ./outputs/${experiment_name}/${now:%Y-%m-%d_%H-%M-%S}

log_every_n_steps: 500

accelerator: cpu
devices: 1

max_epochs: 9

```

Refer to  [lightning Trainer](). And see what options can be specified to perform different training.
