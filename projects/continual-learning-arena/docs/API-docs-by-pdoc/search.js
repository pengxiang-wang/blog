window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "clarena", "modulename": "clarena", "kind": "module", "doc": "<h1 id=\"welcome-to-clarena\">Welcome to CLArena</h1>\n\n<p><strong>CLArena (Continual Learning Arena)</strong> is a open-source Python package for Continual Learning (CL) research, solely developed by myself. In this package, I provide a integrated environment and various APIs to conduct CL experiments for research purposes, as well as implemented CL algorithms and datasets that you can give it a spin immediately.</p>\n\n<p>Please note that this is an API documantation providing detailed information about the available classes, functions, and modules in CLArena. Please refer to the main documentation and my beginners' guide to continual learning for more intuitive tutorials, examples, and guides on how to use CLArena.</p>\n\n<ul>\n<li><strong>Main documentation:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/\">https://pengxiang-wang.com/projects/continual-learning-arena/</a></li>\n<li><strong>A beginners' guide to continual learning:</strong> <a href=\"https://pengxiang-wang.com/posts/continual-learning-beginners-guide\">https://pengxiang-wang.com/posts/continual-learning-beginners-guide</a></li>\n</ul>\n\n<p>We provide various components of continual learning system in the submodules:</p>\n\n<ul>\n<li><code>clarena.cl_datasets</code>: Continual learning datasets.</li>\n<li><code>clarena.backbones</code>: Neural network architectures used as backbones for CL algorithms.</li>\n<li><code>clarena.cl_heads</code>: Multi-head classifiers for continual learning outputs. Task-Incremental Learning (TIL) head and Class-Incremental Learning (CIL) head are included.</li>\n<li><code>clarena.cl_algorithms</code>: Implementations of various continual learning algorithms.</li>\n<li><code>clarena.optimizers</code>: Custom optimizers tailored for continual learning.</li>\n<li><code>clarena.callbacks</code>: Extra functionality or action added in the continual learning process.</li>\n</ul>\n\n<p>As well as the base class in the outmost directory of the package:</p>\n\n<ul>\n<li>Class <code>CLExperiment</code>: The base class for continual learning experiments.</li>\n</ul>\n"}, {"fullname": "clarena.CLExperiment", "modulename": "clarena", "qualname": "CLExperiment", "kind": "class", "doc": "<p>The base class for continual learning experiments.</p>\n"}, {"fullname": "clarena.CLExperiment.__init__", "modulename": "clarena", "qualname": "CLExperiment.__init__", "kind": "function", "doc": "<p>Initializes the CL experiment object with a complete configuration.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>cfg</strong> (<code>DictConfig</code>): the complete config dict for the CL experiment.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cfg</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span></span>)</span>"}, {"fullname": "clarena.CLExperiment.cfg", "modulename": "clarena", "qualname": "CLExperiment.cfg", "kind": "variable", "doc": "<p>Store the complete config dict for any future reference.</p>\n", "annotation": ": omegaconf.dictconfig.DictConfig"}, {"fullname": "clarena.CLExperiment.cl_paradigm", "modulename": "clarena", "qualname": "CLExperiment.cl_paradigm", "kind": "variable", "doc": "<p>Store the continual learning paradigm, either 'TIL' (Task-Incremental Learning) or 'CIL' (Class-Incremental Learning). Parsed from config and used to instantiate the correct heads object and set up CL dataset.</p>\n", "annotation": ": str"}, {"fullname": "clarena.CLExperiment.num_tasks", "modulename": "clarena", "qualname": "CLExperiment.num_tasks", "kind": "variable", "doc": "<p>Store the number of tasks to be conducted in this experiment. Parsed from config and used in the tasks loop.</p>\n", "annotation": ": int"}, {"fullname": "clarena.CLExperiment.test", "modulename": "clarena", "qualname": "CLExperiment.test", "kind": "variable", "doc": "<p>Store whether to test the model after training and validation. Parsed from config and used in the tasks loop.</p>\n", "annotation": ": bool"}, {"fullname": "clarena.CLExperiment.output_dir_name", "modulename": "clarena", "qualname": "CLExperiment.output_dir_name", "kind": "variable", "doc": "<p>Store the name of the output directory to store the logs and checkpoints. Parsed from config and help any output operation to locate the correct directory.</p>\n", "annotation": ": str"}, {"fullname": "clarena.CLExperiment.task_id", "modulename": "clarena", "qualname": "CLExperiment.task_id", "kind": "variable", "doc": "<p>Task ID counter indicating which task is being processed. Self updated during the task loop.</p>\n", "annotation": ": int"}, {"fullname": "clarena.CLExperiment.cl_dataset", "modulename": "clarena", "qualname": "CLExperiment.cl_dataset", "kind": "variable", "doc": "<p>CL dataset object. Instantiate in <code>instantiate_cl_dataset()</code>.</p>\n", "annotation": ": clarena.cl_datasets.base.CLDataset"}, {"fullname": "clarena.CLExperiment.backbone", "modulename": "clarena", "qualname": "CLExperiment.backbone", "kind": "variable", "doc": "<p>Backbone network object. Instantiate in <code>instantiate_backbone()</code>.</p>\n", "annotation": ": clarena.backbones.base.CLBackbone"}, {"fullname": "clarena.CLExperiment.heads", "modulename": "clarena", "qualname": "CLExperiment.heads", "kind": "variable", "doc": "<p>CL output heads object. Instantiate in <code>instantiate_heads()</code>.</p>\n", "annotation": ": clarena.cl_heads.heads_til.HeadsTIL | clarena.cl_heads.heads_cil.HeadsCIL"}, {"fullname": "clarena.CLExperiment.model", "modulename": "clarena", "qualname": "CLExperiment.model", "kind": "variable", "doc": "<p>CL model object. Instantiate in <code>instantiate_cl_algorithm()</code>.</p>\n", "annotation": ": clarena.cl_algorithms.base.CLAlgorithm"}, {"fullname": "clarena.CLExperiment.optimizer", "modulename": "clarena", "qualname": "CLExperiment.optimizer", "kind": "variable", "doc": "<p>Optimizer object for current task <code>self.task_id</code>. Instantiate in <code>instantiate_optimizer()</code>.</p>\n", "annotation": ": torch.optim.optimizer.Optimizer"}, {"fullname": "clarena.CLExperiment.trainer", "modulename": "clarena", "qualname": "CLExperiment.trainer", "kind": "variable", "doc": "<p>Trainer object for current task <code>self.task_id</code>. Instantiate in <code>instantiate_trainer()</code>.</p>\n", "annotation": ": lightning.pytorch.trainer.trainer.Trainer"}, {"fullname": "clarena.CLExperiment.lightning_loggers", "modulename": "clarena", "qualname": "CLExperiment.lightning_loggers", "kind": "variable", "doc": "<p>The list of initialised lightning loggers objects for current task <code>self.task_id</code>. Instantiate in <code>instantiate_lightning_loggers()</code>.</p>\n", "annotation": ": list[lightning.pytorch.loggers.logger.Logger]"}, {"fullname": "clarena.CLExperiment.callbacks", "modulename": "clarena", "qualname": "CLExperiment.callbacks", "kind": "variable", "doc": "<p>The list of initialised callbacks objects for current task <code>self.task_id</code>. Instantiate in <code>instantiate_callbacks()</code>.</p>\n", "annotation": ": list[lightning.pytorch.callbacks.callback.Callback]"}, {"fullname": "clarena.CLExperiment.sanity_check", "modulename": "clarena", "qualname": "CLExperiment.sanity_check", "kind": "function", "doc": "<p>Check the sanity of the config dict <code>self.cfg</code>.</p>\n\n<p><strong>Raises:</strong></p>\n\n<ul>\n<li><strong>KeyError</strong>: when required fields in experiment config are missing, including <code>cl_paradigm</code>, <code>num_tasks</code>, <code>test</code>, <code>output_dir_name</code>.</li>\n<li><strong>ValueError</strong>: when the value of <code>cl_paradigm</code> is not 'TIL' or 'CIL', or when the number of tasks is larger than the number of tasks in the CL dataset.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_cl_dataset", "modulename": "clarena", "qualname": "CLExperiment.instantiate_cl_dataset", "kind": "function", "doc": "<p>Instantiate the CL dataset object from cl_dataset config.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>cl_dataset_cfg</strong> (<code>DictConfig</code>): the cl_dataset config dict.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">cl_dataset_cfg</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_backbone", "modulename": "clarena", "qualname": "CLExperiment.instantiate_backbone", "kind": "function", "doc": "<p>Instantiate the CL backbone network object from backbone config.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>backbone_cfg</strong> (<code>DictConfig</code>): the backbone config dict.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">backbone_cfg</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_heads", "modulename": "clarena", "qualname": "CLExperiment.instantiate_heads", "kind": "function", "doc": "<p>Instantiate the CL output heads object according to field <code>cl_paradigm</code> and backbone <code>output_dim</code> in the config.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>cl_paradigm</strong> (<code>str</code>): the CL paradigm, either 'TIL' or 'CIL'.</li>\n<li><strong>input_dim</strong> (<code>int</code>): the input dimension of the heads. Must be equal to the <code>output_dim</code> of the connected backbone.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">cl_paradigm</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">input_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_cl_algorithm", "modulename": "clarena", "qualname": "CLExperiment.instantiate_cl_algorithm", "kind": "function", "doc": "<p>Instantiate the cl_algorithm object from cl_algorithm config.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>cl_algorithm_cfg</strong> (<code>DictConfig</code>): the cl_algorithm config dict.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">cl_algorithm_cfg</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_optimizer", "modulename": "clarena", "qualname": "CLExperiment.instantiate_optimizer", "kind": "function", "doc": "<p>Instantiate the optimizer object for task <code>task_id</code> from optimizer config.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>optimizer_cfg</strong> (<code>DictConfig</code> or <code>ListConfig</code>): the optimizer config dict. If it's a <code>ListConfig</code>, it should contain optimizer config for each task; otherwise, it's an uniform optimizer config for all tasks.</li>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">optimizer_cfg</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span> <span class=\"o\">|</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">listconfig</span><span class=\"o\">.</span><span class=\"n\">ListConfig</span>,</span><span class=\"param\">\t<span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_trainer", "modulename": "clarena", "qualname": "CLExperiment.instantiate_trainer", "kind": "function", "doc": "<p>Instantiate the trainer object for task <code>task_id</code> from trainer config.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>trainer_cfg</strong> (<code>DictConfig</code>): the trainer config dict. All tasks share the same trainer config but different objects.</li>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">trainer_cfg</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_lightning_loggers", "modulename": "clarena", "qualname": "CLExperiment.instantiate_lightning_loggers", "kind": "function", "doc": "<p>Instantiate the list of lightning loggers objects for task <code>task_id</code> from lightning_loggers config.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>lightning_loggers_cfg</strong> (<code>DictConfig</code>): the lightning_loggers config dict. All tasks share the same lightning_loggers config but different objects.</li>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">lightning_loggers_cfg</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>,</span><span class=\"param\">\t<span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_callbacks", "modulename": "clarena", "qualname": "CLExperiment.instantiate_callbacks", "kind": "function", "doc": "<p>Instantiate the list of callbacks objects for task <code>task_id</code> from callbacks config.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>callbacks_cfg</strong> (<code>DictConfig</code>): the callbacks config dict. All tasks share the same callbacks config but different objects.</li>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">callbacks_cfg</span><span class=\"p\">:</span> <span class=\"n\">omegaconf</span><span class=\"o\">.</span><span class=\"n\">dictconfig</span><span class=\"o\">.</span><span class=\"n\">DictConfig</span>,</span><span class=\"param\">\t<span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.setup_task_id", "modulename": "clarena", "qualname": "CLExperiment.setup_task_id", "kind": "function", "doc": "<p>Set up current task_id in the beginning of the continual learning process of a new task.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): current task_id.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_global", "modulename": "clarena", "qualname": "CLExperiment.instantiate_global", "kind": "function", "doc": "<p>Instantiate global components for the entire CL experiment from <code>self.cfg</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.setup_global", "modulename": "clarena", "qualname": "CLExperiment.setup_global", "kind": "function", "doc": "<p>Let CL dataset know the CL paradigm to define its CL class map.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.instantiate_task_specific", "modulename": "clarena", "qualname": "CLExperiment.instantiate_task_specific", "kind": "function", "doc": "<p>Instantiate task-specific components for the current task <code>self.task_id</code> from <code>self.cfg</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.setup_task_specific", "modulename": "clarena", "qualname": "CLExperiment.setup_task_specific", "kind": "function", "doc": "<p>Setup task-specific components to get ready for the current task <code>self.task_id</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.fit_task", "modulename": "clarena", "qualname": "CLExperiment.fit_task", "kind": "function", "doc": "<p>Fit the model on the current task <code>self.task_id</code>. Also test the model if <code>self.test</code> is set to True.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.CLExperiment.fit", "modulename": "clarena", "qualname": "CLExperiment.fit", "kind": "function", "doc": "<p>The main method to run the continual learning experiment.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.backbones", "modulename": "clarena.backbones", "kind": "module", "doc": "<h1 id=\"backbone-networks-for-continual-learning\">Backbone Networks for Continual Learning</h1>\n\n<p>This submodule provides the <strong>neural network architectures</strong> for continual learning** that can be used in CLArena. </p>\n\n<p>Please note that this is an API documantation. Please refer to the main documentation page for more information about the backbone networks and how to use and customize them:</p>\n\n<ul>\n<li><strong>Configure your backbone network:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/backbone-network\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/backbone-network</a></li>\n<li><strong>Implement your backbone network:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/implement-your-cl-modules/backbone-network\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/implement-your-cl-modules/backbone-network</a></li>\n</ul>\n"}, {"fullname": "clarena.backbones.CLBackbone", "modulename": "clarena.backbones", "qualname": "CLBackbone", "kind": "class", "doc": "<p>The base class of continual learning backbone networks, inherited from <code>torch.nn.Module</code>.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "clarena.backbones.CLBackbone.__init__", "modulename": "clarena.backbones", "qualname": "CLBackbone.__init__", "kind": "function", "doc": "<p>Initialise the CL backbone network.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>output_dim</strong> (<code>int</code>): The output dimension which connects to CL output heads. The <code>input_dim</code> of output heads are expected to be the same as this <code>output_dim</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">output_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "clarena.backbones.CLBackbone.output_dim", "modulename": "clarena.backbones", "qualname": "CLBackbone.output_dim", "kind": "variable", "doc": "<p>Store the output dimension of the backbone network.</p>\n"}, {"fullname": "clarena.backbones.CLBackbone.task_id", "modulename": "clarena.backbones", "qualname": "CLBackbone.task_id", "kind": "variable", "doc": "<p>Task ID counter indicating which task is being processed. Self updated during the task loop.</p>\n", "annotation": ": int"}, {"fullname": "clarena.backbones.CLBackbone.setup_task_id", "modulename": "clarena.backbones", "qualname": "CLBackbone.setup_task_id", "kind": "function", "doc": "<p>Set up which task's dataset the CL experiment is on. This must be done before <code>forward()</code> method is called.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.backbones.CLBackbone.forward", "modulename": "clarena.backbones", "qualname": "CLBackbone.forward", "kind": "function", "doc": "<p>The forward pass for data from task <code>task_id</code>. In some backbones, the forward pass might be different for different tasks.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>input</strong> (<code>Tensor</code>): The input tensor from data.</li>\n<li><strong>task_id</strong> (<code>int</code>): the task ID where the data are from. In TIL, the task IDs of test data are provided thus this argument can be used. In CIL, they are not provided, so it is just a placeholder for API consistence but never used, and best practices are not to provide this argument and leave it as the default value.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The output feature tensor to be passed into heads.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.backbones.mlp", "modulename": "clarena.backbones.mlp", "kind": "module", "doc": "<p>The submodule in <code>backbones</code> for MLP backbone network.</p>\n"}, {"fullname": "clarena.backbones.mlp.MLP", "modulename": "clarena.backbones.mlp", "qualname": "MLP", "kind": "class", "doc": "<p>Multi-Layer Perceptron a.k.a. Fully-Connected Network.</p>\n\n<p>Modified from <code>torchvision.ops.MLP</code> in accordance with this framework.</p>\n", "bases": "clarena.backbones.base.CLBackbone"}, {"fullname": "clarena.backbones.mlp.MLP.__init__", "modulename": "clarena.backbones.mlp", "qualname": "MLP.__init__", "kind": "function", "doc": "<p>Initialise the MLP backbone network.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>input_dim</strong> (<code>int</code>): the input dimension. Any data need to be flattened before going in MLP. Note that it is not required in convolutional networks.</li>\n<li><strong>hidden_dims</strong> (<code>list[int]</code>): list of hidden layer dimensions. It can be empty list which means single-layer MLP, and it can be as many layers as you want. Note that it doesn't include the last dimension which we take as output dimension.</li>\n<li><strong>output_dim</strong> (<code>int</code>): the output dimension which connects to CL output heads.</li>\n<li><strong>activation_layer</strong> (<code>Callable[..., torch.nn.Module]</code> | <code>None</code>): activation function of each layer (if not <code>None</code>), if <code>None</code> this layer won't be used.</li>\n<li><strong>bias</strong> (<code>bool</code>): whether to use bias in the linear layer. Default <code>True</code>.</li>\n<li><strong>dropout</strong> (<code>float</code>): The probability for the dropout layer. Default: 0.0.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">input_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_dims</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">output_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\tactivation_layer: Optional[Callable[..., torch.nn.modules.module.Module]] = &lt;class &#x27;torch.nn.modules.activation.ReLU&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">bias</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span></span>)</span>"}, {"fullname": "clarena.backbones.mlp.MLP.mlp", "modulename": "clarena.backbones.mlp", "qualname": "MLP.mlp", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "clarena.backbones.mlp.MLP.forward", "modulename": "clarena.backbones.mlp", "qualname": "MLP.forward", "kind": "function", "doc": "<p>The forward pass for data. It is the same for all tasks.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>input</strong> (<code>Tensor</code>): The input tensor from data.</li>\n<li><strong>task_id</strong> (<code>int</code>): the task ID where the data are from. It is just a placeholder for API consistence but never used.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The output feature tensor to be passed into heads.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.callbacks", "modulename": "clarena.callbacks", "kind": "module", "doc": "<h1 id=\"callbacks\">Callbacks</h1>\n\n<p>This submodule provides <strong>callbacks</strong> that can be used in CLArena. </p>\n\n<p>Please note that this is an API documantation. Please refer to the main documentation page for more information about the callbacks and how to use and customize them:</p>\n\n<ul>\n<li><strong>Configure your callbacks:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/callbacks\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/callbacks</a></li>\n<li><strong>Implement your callbacks:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/implement-your-cl-modules/callbacks\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/implement-your-cl-modules/callbacks</a></li>\n</ul>\n"}, {"fullname": "clarena.cl_algorithms", "modulename": "clarena.cl_algorithms", "kind": "module", "doc": "<h1 id=\"continual-learning-algorithms\">Continual Learning Algorithms</h1>\n\n<p>This submodule provides the <strong>continual learning algorithms</strong> in CLArena. </p>\n\n<p>Please note that this is an API documantation. Please refer to the main documentation page for more information about the backbone networks and how to use and customize them:</p>\n\n<ul>\n<li><strong>Configure your CL algorithm:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/cl-algorithm\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/cl-algorithm</a></li>\n<li><strong>Implement your CL algorithm:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/implement-your-cl-modules/cl-algorithm\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/implement-your-cl-modules/cl-algorithm</a></li>\n<li><strong>A beginners' guide to continual learning (CL algorithm):</strong> <a href=\"https://pengxiang-wang.com/posts/continual-learning-beginners-guide#methodology\">https://pengxiang-wang.com/posts/continual-learning-beginners-guide#methodology</a></li>\n</ul>\n"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm", "kind": "class", "doc": "<p>The base class of continual learning algorithms, inherited from <code>LightningModule</code>.</p>\n", "bases": "lightning.pytorch.core.module.LightningModule"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.__init__", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.__init__", "kind": "function", "doc": "<p>Initialise the CL algorithm with the network.</p>\n\n<p>Args:</p>\n\n<ul>\n<li><strong>backbone</strong> (<code>CLBackbone</code>): backbone network.</li>\n<li><strong>heads</strong> (<code>HeadsTIL</code> | <code>HeadsCIL</code>): output heads.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">backbone</span><span class=\"p\">:</span> <span class=\"n\">clarena</span><span class=\"o\">.</span><span class=\"n\">backbones</span><span class=\"o\">.</span><span class=\"n\">base</span><span class=\"o\">.</span><span class=\"n\">CLBackbone</span>,</span><span class=\"param\">\t<span class=\"n\">heads</span><span class=\"p\">:</span> <span class=\"n\">clarena</span><span class=\"o\">.</span><span class=\"n\">cl_heads</span><span class=\"o\">.</span><span class=\"n\">heads_til</span><span class=\"o\">.</span><span class=\"n\">HeadsTIL</span> <span class=\"o\">|</span> <span class=\"n\">clarena</span><span class=\"o\">.</span><span class=\"n\">cl_heads</span><span class=\"o\">.</span><span class=\"n\">heads_cil</span><span class=\"o\">.</span><span class=\"n\">HeadsCIL</span></span>)</span>"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.backbone", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.backbone", "kind": "variable", "doc": "<p>Store the backbone network.</p>\n", "annotation": ": clarena.backbones.base.CLBackbone"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.heads", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.heads", "kind": "variable", "doc": "<p>Store the output heads.</p>\n", "annotation": ": clarena.cl_heads.heads_til.HeadsTIL | clarena.cl_heads.heads_cil.HeadsCIL"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.optimizer", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.optimizer", "kind": "variable", "doc": "<p>Store the optimizer object (partially initialised) for the backpropagation of task <code>self.task_id</code>. Will be equipped with parameters in <code>configure_optimizers()</code>.</p>\n", "annotation": ": torch.optim.optimizer.Optimizer"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.criterion", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.criterion", "kind": "variable", "doc": "<p>The loss function bewteen the output logits and the target labels. Default is cross-entropy loss.</p>\n"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.task_id", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.task_id", "kind": "variable", "doc": "<p>Task ID counter indicating which task is being processed. Self updated during the task loop.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.sanity_check", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.sanity_check", "kind": "function", "doc": "<p>Check the sanity of the arguments.</p>\n\n<p><strong>Raises:</strong></p>\n\n<ul>\n<li><strong>ValueError</strong>: if the <code>output_dim</code> of backbone network is not equal to the <code>input_dim</code> of CL heads.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.setup_task_id", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.setup_task_id", "kind": "function", "doc": "<p>Set up which task's dataset the CL experiment is on. This must be done before <code>forward()</code> method is called.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n<li><strong>num_classes_t</strong> (<code>int</code>): the number of classes in the task.</li>\n<li><strong>optimizer</strong> (<code>Optimizer</code>): the optimizer object (partially initialised) for the task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_classes_t</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">optimizer</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">Optimizer</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.forward", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.forward", "kind": "function", "doc": "<p>The default forward pass for data from task <code>task_id</code>. Note that it is nothing to do with <code>forward()</code> method in <code>nn.Module</code>.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>input</strong> (<code>Tensor</code>): The input tensor from data.</li>\n<li><strong>task_id</strong> (<code>int</code>): the task ID where the data are from.</li>\n</ul>\n\n<p>Returns:</p>\n\n<ul>\n<li>The output logits tensor.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_algorithms.CLAlgorithm.configure_optimizers", "modulename": "clarena.cl_algorithms", "qualname": "CLAlgorithm.configure_optimizers", "kind": "function", "doc": "<p>Configure optimizer hooks by Lightning.\nSee <a href=\"https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#configure-optimizers\">Lightning docs</a> for more details.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">Optimizer</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_algorithms.finetuning", "modulename": "clarena.cl_algorithms.finetuning", "kind": "module", "doc": "<p>The submodule in <code>cl_algorithms</code> for Finetuning algorithm.</p>\n"}, {"fullname": "clarena.cl_algorithms.finetuning.Finetuning", "modulename": "clarena.cl_algorithms.finetuning", "qualname": "Finetuning", "kind": "class", "doc": "<p>Finetuning algorithm.</p>\n\n<p>It is the most naive way for task-incremental learning. It simply initialises the backbone from the last task when training new task.</p>\n", "bases": "clarena.cl_algorithms.base.CLAlgorithm"}, {"fullname": "clarena.cl_algorithms.finetuning.Finetuning.__init__", "modulename": "clarena.cl_algorithms.finetuning", "qualname": "Finetuning.__init__", "kind": "function", "doc": "<p>Initialise the Finetuning algorithm with the network. It has no additional hyperparamaters.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>backbone</strong> (<code>CLBackbone</code>): backbone network.</li>\n<li><strong>heads</strong> (<code>HeadsTIL</code> | <code>HeadsCIL</code>): output heads.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">backbone</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">heads</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span></span>)</span>"}, {"fullname": "clarena.cl_algorithms.finetuning.Finetuning.training_step", "modulename": "clarena.cl_algorithms.finetuning", "qualname": "Finetuning.training_step", "kind": "function", "doc": "<p>Training step for current task <code>self.task_id</code>.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>batch</strong> (<code>Any</code>): a batch of training data.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Any</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_algorithms.finetuning.Finetuning.validation_step", "modulename": "clarena.cl_algorithms.finetuning", "qualname": "Finetuning.validation_step", "kind": "function", "doc": "<p>Validation step for current task <code>self.task_id</code>.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>batch</strong> (<code>Any</code>): a batch of validation data.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">Any</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_algorithms.finetuning.Finetuning.test_step", "modulename": "clarena.cl_algorithms.finetuning", "qualname": "Finetuning.test_step", "kind": "function", "doc": "<p>Test step for current task <code>self.task_id</code>, which tests for all seen tasks indexed by <code>dataloader_idx</code>.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>batch</strong> (<code>Any</code>): a batch of test data.</li>\n<li><strong>dataloader_idx</strong> (<code>int</code>): the task ID of seen tasks to be tested. A default value of 0 is given otherwise the LightningModule will raise a <code>RuntimeError</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>,</span><span class=\"param\">\t<span class=\"n\">batch_idx</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dataloader_idx</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">0</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets", "modulename": "clarena.cl_datasets", "kind": "module", "doc": "<h1 id=\"continual-learning-datasets\">Continual Learning Datasets</h1>\n\n<p>This submodule provides the <strong>continual learning datasets</strong> that can be used in CLArena. </p>\n\n<p>Please note that this is an API documantation. Please refer to the main documentation page for more information about the CL datasets and how to use and customize them:</p>\n\n<ul>\n<li><strong>Configure your CL dataset:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/cl-dataset\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/cl-dataset</a></li>\n<li><strong>Implement your CL dataset:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/implement-your-cl-modules/cl-dataset\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/implement-your-cl-modules/cl-dataset</a></li>\n<li><strong>A beginners' guide to continual learning (CL dataset):</strong> <a href=\"https://pengxiang-wang.com/posts/continual-learning-beginners-guide#CL-dataset\">https://pengxiang-wang.com/posts/continual-learning-beginners-guide#CL-dataset</a></li>\n</ul>\n\n<p>The datasets are implemented as subclasses of <code>CLDataset</code> classes, which are the base class for all continual learning datasets in CLArena.</p>\n\n<ul>\n<li><code>CLDataset</code>: The base class for continual learning datasets.</li>\n<li><code>CLPermutedDataset</code>: The base class for permuted continual learning datasets. A child class of <code>CLDataset</code>.</li>\n</ul>\n"}, {"fullname": "clarena.cl_datasets.CLDataset", "modulename": "clarena.cl_datasets", "qualname": "CLDataset", "kind": "class", "doc": "<p>The base class of continual learning datasets, inherited from <code>LightningDataModule</code>.</p>\n", "bases": "lightning.pytorch.core.datamodule.LightningDataModule"}, {"fullname": "clarena.cl_datasets.CLDataset.__init__", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.__init__", "kind": "function", "doc": "<p>Initialise the CL dataset object providing the root where data files live.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>root</strong> (<code>str</code>): the root directory where the original data files for constructing the CL dataset physically live.</li>\n<li><strong>num_tasks</strong> (<code>int</code>): the maximum number of tasks supported by the CL dataset.</li>\n<li><strong>validation_percentage</strong> (<code>float</code>): the percentage to randomly split some of the training data into validation data.</li>\n<li><strong>batch_size</strong> (<code>int</code>): The batch size in train, val, test dataloader.</li>\n<li><strong>num_workers</strong> (<code>int</code>): the number of workers for dataloaders.</li>\n<li><strong>custom_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom transforms to apply to ONLY TRAIN dataset. Can be a single transform, composed transforms or no transform. <code>ToTensor()</code>, normalise, permute and so on are not included.</li>\n<li><strong>custom_target_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom target transforms to apply to dataset labels. Can be a single transform, composed transforms or no transform. CL class mapping is not included.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">root</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">num_tasks</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">validation_percentage</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">custom_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">custom_target_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "clarena.cl_datasets.CLDataset.root", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.root", "kind": "variable", "doc": "<p>Store the root directory of the original data files. Used when constructing the dataset.</p>\n", "annotation": ": str"}, {"fullname": "clarena.cl_datasets.CLDataset.num_tasks", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.num_tasks", "kind": "variable", "doc": "<p>Store the maximum number of tasks supported by the dataset.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_datasets.CLDataset.validation_percentage", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.validation_percentage", "kind": "variable", "doc": "<p>Store the percentage to randomly split some of the training data into validation data.</p>\n", "annotation": ": float"}, {"fullname": "clarena.cl_datasets.CLDataset.batch_size", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.batch_size", "kind": "variable", "doc": "<p>Store the batch size. Used when constructing train, val, test dataloader.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_datasets.CLDataset.num_workers", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.num_workers", "kind": "variable", "doc": "<p>Store the number of workers. Used when constructing train, val, test dataloader.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_datasets.CLDataset.custom_transforms", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.custom_transforms", "kind": "variable", "doc": "<p>Store the custom transforms other than the basics. Used when constructing the dataset.</p>\n", "annotation": ": Union[Callable, torchvision.transforms.transforms.Compose, NoneType]"}, {"fullname": "clarena.cl_datasets.CLDataset.custom_target_transforms", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.custom_target_transforms", "kind": "variable", "doc": "<p>Store the custom target transforms other than the CL class mapping. Used when constructing the dataset.</p>\n", "annotation": ": Union[Callable, torchvision.transforms.transforms.Compose, NoneType]"}, {"fullname": "clarena.cl_datasets.CLDataset.task_id", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.task_id", "kind": "variable", "doc": "<p>Task ID counter indicating which task is being processed. Self updated during the task loop.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_datasets.CLDataset.cl_paradigm", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.cl_paradigm", "kind": "variable", "doc": "<p>Store the continual learning paradigm, either 'TIL' (Task-Incremental Learning) or 'CIL' (Class-Incremental Learning). Gotten from <code>set_cl_paradigm</code> and used to define the CL class map.</p>\n", "annotation": ": str"}, {"fullname": "clarena.cl_datasets.CLDataset.cl_class_map_t", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.cl_class_map_t", "kind": "variable", "doc": "<p>Store the CL class map for the current task <code>self.task_id</code>.</p>\n", "annotation": ": dict[str | int, int]"}, {"fullname": "clarena.cl_datasets.CLDataset.cl_class_mapping_t", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.cl_class_mapping_t", "kind": "variable", "doc": "<p>Store the CL class mapping transform for the current task <code>self.task_id</code>.</p>\n", "annotation": ": Callable"}, {"fullname": "clarena.cl_datasets.CLDataset.dataset_train", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.dataset_train", "kind": "variable", "doc": "<p>The training dataset object. Can be a PyTorch Dataset object or any other dataset object.</p>\n", "annotation": ": object"}, {"fullname": "clarena.cl_datasets.CLDataset.dataset_val", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.dataset_val", "kind": "variable", "doc": "<p>The validation dataset object. Can be a PyTorch Dataset object or any other dataset object.</p>\n", "annotation": ": object"}, {"fullname": "clarena.cl_datasets.CLDataset.dataset_test", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.dataset_test", "kind": "variable", "doc": "<p>The dictionary to store test dataset object. Key is task_id, value is the dataset object. Can be a PyTorch Dataset object or any other dataset object.</p>\n", "annotation": ": dict[int, object]"}, {"fullname": "clarena.cl_datasets.CLDataset.sanity_check", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.sanity_check", "kind": "function", "doc": "<p>Check the sanity of the arguments.</p>\n\n<p><strong>Raises:</strong></p>\n\n<ul>\n<li><strong>ValueError</strong>: when the <code>validation_percentage</code> is not in the range of 0-1.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.cl_class_map", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.cl_class_map", "kind": "function", "doc": "<p>The mapping of classes of task <code>task_id</code> to fit continual learning settings <code>self.cl_paradigm</code>. It must be implemented by subclasses.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): The task ID to query CL class map.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The CL class map of the task. Key is original class label, value is integer class label for continual learning.\n<ul>\n<li>If <code>self.cl_paradigm</code> is 'TIL', the mapped class labels of a task should be continuous integers from 0 to the number of classes.</li>\n<li>If <code>self.cl_paradigm</code> is 'CIL', the mapped class labels of a task should be continuous integers from the number of classes of previous tasks to the number of classes of the current task.</li>\n</ul></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span> <span class=\"o\">|</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.prepare_data", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.prepare_data", "kind": "function", "doc": "<p>Use this to download and prepare data. It must be implemented by subclasses, regulated by <code>LightningDatamodule</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.setup", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.setup", "kind": "function", "doc": "<p>Set up the dataset for different stages.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>stage</strong> (<code>str</code>): the stage of the experiment. Should be one of the following:\n<ul>\n<li>'fit' or 'validate': training and validation dataset of current task <code>self.task_id</code> should be assigned to <code>self.dataset_train</code> and <code>self.dataset_val</code>.</li>\n<li>'test': a list of test dataset of all seen tasks (from task 0 to <code>self.task_id</code>) should be assigned to <code>self.dataset_test</code>.</li>\n</ul></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">stage</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.setup_task_id", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.setup_task_id", "kind": "function", "doc": "<p>Set up which task's dataset the CL experiment is on. This must be done before <code>setup()</code> method is called.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.set_cl_paradigm", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.set_cl_paradigm", "kind": "function", "doc": "<p>Set the continual learning paradigm to <code>self.cl_paradigm</code>. It is used to define the CL class map.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>cl_paradigm</strong> (<code>str</code>): the continual learning paradigmeither 'TIL' (Task-Incremental Learning) or 'CIL' (Class-Incremental Learning).</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">cl_paradigm</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.mean", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.mean", "kind": "function", "doc": "<p>The mean values for normalisation of task <code>task_id</code>. Used when constructing the dataset.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The mean values for normalisation.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.std", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.std", "kind": "function", "doc": "<p>The standard deviation values for normalisation of task <code>task_id</code>. Used when constructing the dataset.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The standard deviation values for normalisation.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.train_and_val_transforms", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.train_and_val_transforms", "kind": "function", "doc": "<p>Transforms generator for train and validation dataset incorporating the custom transforms with basic transforms like <code>normalisation</code> and <code>ToTensor()</code>. It is a handy tool to use in subclasses when constructing the dataset.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>to_tensor</strong> (<code>bool</code>): whether to include <code>ToTensor()</code> transform.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The composed training transforms.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">to_tensor</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.test_transforms", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.test_transforms", "kind": "function", "doc": "<p>Transforms generator for test dataset. Only basic transforms like <code>normalisation</code> and <code>ToTensor()</code> are included. It is a handy tool to use in subclasses when constructing the dataset.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>to_tensor</strong> (<code>bool</code>): whether to include <code>ToTensor()</code> transform.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The composed training transforms.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">to_tensor</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.target_transforms", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.target_transforms", "kind": "function", "doc": "<p>The target transform for the dataset. It is a handy tool to use in subclasses when constructing the dataset.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>target</strong> (<code>Tensor</code>): the target tensor.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The transformed target tensor.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.train_and_val_dataset", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.train_and_val_dataset", "kind": "function", "doc": "<p>Get the training and validation dataset of task <code>self.task_id</code>. It must be implemented by subclasses.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The train and validation dataset of task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">object</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.test_dataset", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.test_dataset", "kind": "function", "doc": "<p>Get the test dataset of task <code>self.task_id</code>. It must be implemented by subclasses.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The test dataset of task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">object</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.train_dataloader", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.train_dataloader", "kind": "function", "doc": "<p>DataLoader generator for stage train of task <code>self.task_id</code>. It is automatically called before training.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The train DataLoader of task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.val_dataloader", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.val_dataloader", "kind": "function", "doc": "<p>DataLoader generator for stage validate. It is automatically called before validating.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The validation DataLoader of task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLDataset.test_dataloader", "modulename": "clarena.cl_datasets", "qualname": "CLDataset.test_dataloader", "kind": "function", "doc": "<p>DataLoader generator for stage test. It is automatically called before testing.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The test DataLoader dict of <code>self.task_id</code> and all tasks before (as the test is conducted on all seen tasks). Key is task_id, value is the DataLoader.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset", "kind": "class", "doc": "<p>The base class of continual learning datasets which are constructed as permutations from an original dataset, inherited from <code>CLDataset</code>.</p>\n", "bases": "clarena.cl_datasets.base.CLDataset"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.__init__", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.__init__", "kind": "function", "doc": "<p>Initialise the CL dataset object providing the root where data files live.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>root</strong> (<code>str</code>): the root directory where the original data files for constructing the CL dataset physically live.</li>\n<li><strong>num_tasks</strong> (<code>int</code>): the maximum number of tasks supported by the CL dataset.</li>\n<li><strong>validation_percentage</strong> (<code>float</code>): the percentage to randomly split some of the training data into validation data.</li>\n<li><strong>batch_size</strong> (<code>int</code>): The batch size in train, val, test dataloader.</li>\n<li><strong>num_workers</strong> (<code>int</code>): the number of workers for dataloaders.</li>\n<li><strong>custom_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom transforms to apply to ONLY TRAIN dataset. Can be a single transform, composed transforms or no transform. <code>ToTensor()</code>, normalise, permute and so on are not included.</li>\n<li><strong>custom_target_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom target transforms to apply to dataset labels. Can be a single transform, composed transforms or no transform. CL class mapping is not included.</li>\n<li><strong>permutation_mode</strong> (<code>str</code>): the mode of permutation, should be one of the following:\n<ol>\n<li>'all': permute all pixels.</li>\n<li>'by_channel': permute channel by channel separately. All channels are applied the same permutation order.</li>\n<li>'first_channel_only': permute only the first channel.</li>\n</ol></li>\n<li><strong>permutation_seeds</strong> (<code>list[int]</code> or <code>None</code>): the seeds for permutation operations used to construct tasks. Make sure it has the same number of seeds as <code>num_tasks</code>. Default is None, which creates a list of seeds from 1 to <code>num_tasks</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">root</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">num_tasks</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">validation_percentage</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">custom_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">custom_target_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">permutation_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;first_channel_only&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">permutation_seeds</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.num_classes", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.num_classes", "kind": "variable", "doc": "<p>The number of classes in the original dataset before permutation. It must be provided in subclasses.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.img_size", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.img_size", "kind": "variable", "doc": "<p>The size of images in the original dataset before permutation. Used when constructing permutation operations. It must be provided in subclasses.</p>\n", "annotation": ": torch.Size"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.mean_original", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.mean_original", "kind": "variable", "doc": "<p>The mean values for normalisation. It must be provided in subclasses.</p>\n", "annotation": ": tuple[float]"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.std_original", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.std_original", "kind": "variable", "doc": "<p>The standard deviation values for normalisation. It must be provided in subclasses.</p>\n", "annotation": ": tuple[float]"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.permutation_mode", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.permutation_mode", "kind": "variable", "doc": "<p>Store the mode of permutation. Used when permutation operations used to construct tasks.</p>\n", "annotation": ": str"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.permutation_seeds", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.permutation_seeds", "kind": "variable", "doc": "<p>Store the permutation seeds for all tasks. Use when permutation operations used to construct tasks.</p>\n", "annotation": ": list[int]"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.permutation_seed_t", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.permutation_seed_t", "kind": "variable", "doc": "<p>Store the permutation seed for the current task <code>self.task_id</code>.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.permute_t", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.permute_t", "kind": "variable", "doc": "<p>Store the permutation transform for the current task <code>self.task_id</code>.</p>\n", "annotation": ": clarena.cl_datasets.base.Permute"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.sanity_check", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.sanity_check", "kind": "function", "doc": "<p>Check the sanity of the arguments.</p>\n\n<p><strong>Raises:</strong></p>\n\n<ul>\n<li><strong>ValueError</strong>: when the <code>permutation_seeds</code> is not equal to <code>num_tasks</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.cl_class_map", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.cl_class_map", "kind": "function", "doc": "<p>The mapping of classes of task <code>task_id</code> to fit continual learning settings <code>self.cl_paradigm</code>.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): The task ID to query CL class map.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The CL class map of the task. Key is original class label, value is integer class label for continual learning.\n<ul>\n<li>If <code>self.cl_paradigm</code> is 'TIL', the mapped class labels of a task should be continuous integers from 0 to the number of classes.</li>\n<li>If <code>self.cl_paradigm</code> is 'CIL', the mapped class labels of a task should be continuous integers from the number of classes of previous tasks to the number of classes of the current task.</li>\n</ul></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span> <span class=\"o\">|</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.setup_task_id", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.setup_task_id", "kind": "function", "doc": "<p>Set up which task's dataset the CL experiment is on. This must be done before <code>setup()</code> method is called.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.mean", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.mean", "kind": "function", "doc": "<p>The mean values for normalisation of task <code>task_id</code>. Used when constructing the dataset. In permuted CL dataset, the mean values are the same as the original dataset.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The mean values for normalisation.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.std", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.std", "kind": "function", "doc": "<p>The standard deviation values for normalisation of task <code>task_id</code>. Used when constructing the dataset. In permuted CL dataset, the mean values are the same as the original dataset.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The standard deviation values for normalisation.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.train_and_val_transforms", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.train_and_val_transforms", "kind": "function", "doc": "<p>Transforms generator for train and validation dataset incorporating the custom transforms with basic transforms like <code>normalisation</code> and <code>ToTensor()</code>. In permuted CL datasets, permute transform also applies. It is a handy tool to use in subclasses when constructing the dataset.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>to_tensor</strong> (<code>bool</code>): whether to include <code>ToTensor()</code> transform.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The composed training transforms.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">to_tensor</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLPermutedDataset.test_transforms", "modulename": "clarena.cl_datasets", "qualname": "CLPermutedDataset.test_transforms", "kind": "function", "doc": "<p>Transforms generator for test dataset. Only basic transforms like <code>normalisation</code> and <code>ToTensor()</code> are included. It is a handy tool to use in subclasses when constructing the dataset.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>to_tensor</strong> (<code>bool</code>): whether to include <code>ToTensor()</code> transform.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The composed training transforms.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">to_tensor</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLSplitDataset", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset", "kind": "class", "doc": "<p>The base class of continual learning datasets, which are constructed as permutations from an original dataset, inherited from <code>CLDataset</code>.</p>\n", "bases": "clarena.cl_datasets.base.CLDataset"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.__init__", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.__init__", "kind": "function", "doc": "<p>Initialise the CL dataset object providing the root where data files live.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>root</strong> (<code>str</code>): the root directory where the original data files for constructing the CL dataset physically live.</li>\n<li><strong>num_tasks</strong> (<code>int</code>): the maximum number of tasks supported by the CL dataset.</li>\n<li><strong>class_split</strong> (<code>list[list[int]]</code>): the class split for each task. Each element in the list is a list of class labels (integers starting from 0) to split for a task.</li>\n<li><strong>validation_percentage</strong> (<code>float</code>): the percentage to randomly split some of the training data into validation data.</li>\n<li><strong>batch_size</strong> (<code>int</code>): The batch size in train, val, test dataloader.</li>\n<li><strong>num_workers</strong> (<code>int</code>): the number of workers for dataloaders.</li>\n<li><strong>custom_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom transforms to apply to ONLY TRAIN dataset. Can be a single transform, composed transforms or no transform. <code>ToTensor()</code>, normalise, permute and so on are not included.</li>\n<li><strong>custom_target_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom target transforms to apply to dataset labels. Can be a single transform, composed transforms or no transform. CL class mapping is not included.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">root</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">num_tasks</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">class_split</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">validation_percentage</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">custom_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">custom_target_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.num_classes", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.num_classes", "kind": "variable", "doc": "<p>The number of classes in the original dataset before permutation. It must be provided in subclasses.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.mean_original", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.mean_original", "kind": "variable", "doc": "<p>The mean values for normalisation. It must be provided in subclasses.</p>\n", "annotation": ": tuple[float]"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.std_original", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.std_original", "kind": "variable", "doc": "<p>The standard deviation values for normalisation. It must be provided in subclasses.</p>\n", "annotation": ": tuple[float]"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.class_split", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.class_split", "kind": "variable", "doc": "<p>Store the class split for each task. Used when constructing the split dataset.</p>\n"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.sanity_check", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.sanity_check", "kind": "function", "doc": "<p>Check the sanity of the arguments.</p>\n\n<p><strong>Raises:</strong></p>\n\n<ul>\n<li><strong>ValueError</strong>: when the length of <code>class_split</code> is not equal to <code>num_tasks</code>.</li>\n<li><strong>ValueError</strong>: when any of the lists in <code>class_split</code> has less than 2 elements. A classification task must have less than 2 classes.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.cl_class_map", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.cl_class_map", "kind": "function", "doc": "<p>The mapping of classes of task <code>task_id</code> to fit continual learning settings <code>self.cl_paradigm</code>.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): The task ID to query CL class map.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The CL class map of the task. Key is original class label, value is integer class label for continual learning.\n<ul>\n<li>If <code>self.cl_paradigm</code> is 'TIL', the mapped class labels of a task should be continuous integers from 0 to the number of classes.</li>\n<li>If <code>self.cl_paradigm</code> is 'CIL', the mapped class labels of a task should be continuous integers from the number of classes of previous tasks to the number of classes of the current task.</li>\n</ul></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span> <span class=\"o\">|</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.mean", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.mean", "kind": "function", "doc": "<p>The mean values for normalisation of task <code>task_id</code>. Used when constructing the dataset. In split CL dataset, the mean values are the same as the original dataset.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The mean values for normalisation.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.std", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.std", "kind": "function", "doc": "<p>The standard deviation values for normalisation of task <code>task_id</code>. Used when constructing the dataset. In split CL dataset, the mean values are the same as the original dataset.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The standard deviation values for normalisation.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLSplitDataset.get_class_subset", "modulename": "clarena.cl_datasets", "qualname": "CLSplitDataset.get_class_subset", "kind": "function", "doc": "<p>Provide a util method here to retrieve a subset from PyTorch Dataset of classes. It could be useful when you constructing the split CL dataset.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>dataset</strong> (<code>Dataset</code>): the original dataset to retrieve subset from.</li>\n<li><strong>classes</strong> (<code>list[int]</code>): the classes of the subset.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li><code>Dataset</code>: subset of original dataset in classes.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">dataset</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span>,</span><span class=\"param\">\t<span class=\"n\">classes</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.CLClassMapping", "modulename": "clarena.cl_datasets", "qualname": "CLClassMapping", "kind": "class", "doc": "<p>CL Class mapping to dataset labels. Used as a PyTorch target Transform.</p>\n"}, {"fullname": "clarena.cl_datasets.CLClassMapping.__init__", "modulename": "clarena.cl_datasets", "qualname": "CLClassMapping.__init__", "kind": "function", "doc": "<p>Initialise the CL class mapping transform object from the CL class map of a task.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>cl_class_map</strong> (<code>dict[str | int, int]</code>): the CL class map for a task.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cl_class_map</span><span class=\"p\">:</span> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span> <span class=\"o\">|</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "clarena.cl_datasets.CLClassMapping.cl_class_map", "modulename": "clarena.cl_datasets", "qualname": "CLClassMapping.cl_class_map", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "clarena.cl_datasets.Permute", "modulename": "clarena.cl_datasets", "qualname": "Permute", "kind": "class", "doc": "<p>Permutation operation to image. Used to construct permuted CL dataset.</p>\n\n<p>Used as a PyTorch Dataset Transform.</p>\n"}, {"fullname": "clarena.cl_datasets.Permute.__init__", "modulename": "clarena.cl_datasets", "qualname": "Permute.__init__", "kind": "function", "doc": "<p>Initialise the Permute transform object. The permutation order is constructed in the initialisation to save runtime.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>img_size</strong> (<code>torch.Size</code>): the size of the image to be permuted.</li>\n<li><strong>mode</strong> (<code>str</code>): the mode of permutation, shouble be one of the following:\n<ul>\n<li>'all': permute all pixels.</li>\n<li>'by_channel': permute channel by channel separately. All channels are applied the same permutation order.</li>\n<li>'first_channel_only': permute only the first channel.</li>\n</ul></li>\n<li><strong>seed</strong> (<code>int</code> or <code>None</code>): seed for permutation operation. If None, the permutation will use a default seed from PyTorch generator.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">img_size</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span>,</span><span class=\"param\">\t<span class=\"n\">mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;first_channel_only&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "clarena.cl_datasets.Permute.mode", "modulename": "clarena.cl_datasets", "qualname": "Permute.mode", "kind": "variable", "doc": "<p>Store the mode of permutation.</p>\n"}, {"fullname": "clarena.cl_datasets.Permute.permute", "modulename": "clarena.cl_datasets", "qualname": "Permute.permute", "kind": "variable", "doc": "<p>The permutation order, a <code>Tensor</code> permuted from [1,2, ..., <code>num_pixels</code>] with the given seed. It is the core element of permutation operation.</p>\n", "annotation": ": torch.Tensor"}, {"fullname": "clarena.cl_datasets.permuted_mnist", "modulename": "clarena.cl_datasets.permuted_mnist", "kind": "module", "doc": "<p>The submodule in <code>cl_datasets</code> for Permuted MNIST dataset.</p>\n"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST", "kind": "class", "doc": "<p>Permuted MNIST dataset.</p>\n", "bases": "clarena.cl_datasets.base.CLPermutedDataset"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST.__init__", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST.__init__", "kind": "function", "doc": "<p>Initialise the Permuted MNIST dataset.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>root</strong> (<code>str</code>): the root directory where the original MNIST data 'MNIST/raw/train-images-idx3-ubyte' and 'MNIST/raw/t10k-images-idx3-ubyte' live.</li>\n<li><strong>num_tasks</strong> (<code>int</code>): the maximum number of tasks supported by the CL dataset.</li>\n<li><strong>validation_percentage</strong> (<code>float</code>): the percentage to randomly split some of the training data into validation data.</li>\n<li><strong>batch_size</strong> (<code>int</code>): The batch size in train, val, test dataloader.</li>\n<li><strong>num_workers</strong> (<code>int</code>): the number of workers for dataloaders.</li>\n<li><strong>custom_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom transforms to apply to ONLY TRAIN dataset. Can be a single transform, composed transforms or no transform.\n<code>ToTensor()</code>, normalise, permute and so on are not included.</li>\n<li><strong>custom_target_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom target transforms to apply to dataset labels. Can be a single transform, composed transforms or no transform. CL class mapping is not included.</li>\n<li><strong>permutation_mode</strong> (<code>str</code>): the mode of permutation, should be one of the following:\n<ol>\n<li>'all': permute all pixels.</li>\n<li>'by_channel': permute channel by channel separately. All channels are applied the same permutation order.</li>\n<li>'first_channel_only': permute only the first channel.</li>\n</ol></li>\n<li><strong>permutation_seeds</strong> (<code>list[int]</code> or <code>None</code>): the seeds for permutation operations used to construct tasks. Make sure it has the same number of seeds as <code>num_tasks</code>. Default is None, which creates a list of seeds from 1 to <code>num_tasks</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">root</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">num_tasks</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">validation_percentage</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">custom_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">custom_target_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">permutation_mode</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;first_channel_only&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">permutation_seeds</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST.num_class", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST.num_class", "kind": "variable", "doc": "<p>The number of classes in MNIST.</p>\n", "annotation": ": int", "default_value": "10"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST.img_size", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST.img_size", "kind": "variable", "doc": "<p>The size of MNIST images.</p>\n", "annotation": ": torch.Size", "default_value": "torch.Size([1, 28, 28])"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST.mean_original", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST.mean_original", "kind": "variable", "doc": "<p>The mean values for normalisation.</p>\n", "annotation": ": tuple[float]", "default_value": "(0.1307,)"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST.std_original", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST.std_original", "kind": "variable", "doc": "<p>The standard deviation values for normalisation.</p>\n", "annotation": ": tuple[float]", "default_value": "(0.3081,)"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST.prepare_data", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST.prepare_data", "kind": "function", "doc": "<p>Download the original MNIST dataset if haven't.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST.train_and_val_dataset", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST.train_and_val_dataset", "kind": "function", "doc": "<p>Get the training and validation dataset of task <code>self.task_id</code>.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The train and validation dataset of task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.permuted_mnist.PermutedMNIST.test_dataset", "modulename": "clarena.cl_datasets.permuted_mnist", "qualname": "PermutedMNIST.test_dataset", "kind": "function", "doc": "<p>Get the test dataset of task <code>self.task_id</code>.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The test dataset of task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.split_cifar100", "modulename": "clarena.cl_datasets.split_cifar100", "kind": "module", "doc": "<p>The submodule in <code>cl_datasets</code> for Split CIFAR100 dataset.</p>\n"}, {"fullname": "clarena.cl_datasets.split_cifar100.SplitCIFAR100", "modulename": "clarena.cl_datasets.split_cifar100", "qualname": "SplitCIFAR100", "kind": "class", "doc": "<p>Split CIFAR100 dataset.</p>\n", "bases": "clarena.cl_datasets.base.CLSplitDataset"}, {"fullname": "clarena.cl_datasets.split_cifar100.SplitCIFAR100.__init__", "modulename": "clarena.cl_datasets.split_cifar100", "qualname": "SplitCIFAR100.__init__", "kind": "function", "doc": "<p>Initialise the Permuted MNIST dataset.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>root</strong> (<code>str</code>): the root directory where the original MNIST data 'MNIST/raw/train-images-idx3-ubyte' and 'MNIST/raw/t10k-images-idx3-ubyte' live.</li>\n<li><strong>num_tasks</strong> (<code>int</code>): the maximum number of tasks supported by the CL dataset.</li>\n<li><strong>class_split</strong> (<code>list[list[int]]</code>): the class split for each task. Each element in the list is a list of class labels (integers starting from 0) to split for a task.</li>\n<li><strong>validation_percentage</strong> (<code>float</code>): the percentage to randomly split some of the training data into validation data.</li>\n<li><strong>batch_size</strong> (<code>int</code>): The batch size in train, val, test dataloader.</li>\n<li><strong>num_workers</strong> (<code>int</code>): the number of workers for dataloaders.</li>\n<li><strong>custom_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom transforms to apply to ONLY TRAIN dataset. Can be a single transform, composed transforms or no transform.\n<code>ToTensor()</code>, normalise, permute and so on are not included.</li>\n<li><strong>custom_target_transforms</strong> (<code>transform</code> or <code>transforms.Compose</code> or <code>None</code>): the custom target transforms to apply to dataset labels. Can be a single transform, composed transforms or no transform. CL class mapping is not included.</li>\n<li><strong>permutation_mode</strong> (<code>str</code>): the mode of permutation, should be one of the following:\n<ol>\n<li>'all': permute all pixels.</li>\n<li>'by_channel': permute channel by channel separately. All channels are applied the same permutation order.</li>\n<li>'first_channel_only': permute only the first channel.</li>\n</ol></li>\n<li><strong>permutation_seeds</strong> (<code>list[int]</code> or <code>None</code>): the seeds for permutation operations used to construct tasks. Make sure it has the same number of seeds as <code>num_tasks</code>. Default is None, which creates a list of seeds from 1 to <code>num_tasks</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">root</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">num_tasks</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">class_split</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">validation_percentage</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">num_workers</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">custom_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">custom_target_transforms</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Callable</span><span class=\"p\">,</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "clarena.cl_datasets.split_cifar100.SplitCIFAR100.num_classes", "modulename": "clarena.cl_datasets.split_cifar100", "qualname": "SplitCIFAR100.num_classes", "kind": "variable", "doc": "<p>The number of classes in CIFAR100 dataset.</p>\n", "annotation": ": int", "default_value": "100"}, {"fullname": "clarena.cl_datasets.split_cifar100.SplitCIFAR100.mean_original", "modulename": "clarena.cl_datasets.split_cifar100", "qualname": "SplitCIFAR100.mean_original", "kind": "variable", "doc": "<p>The mean values for normalisation.</p>\n", "annotation": ": tuple[float]", "default_value": "(0.1307,)"}, {"fullname": "clarena.cl_datasets.split_cifar100.SplitCIFAR100.std_original", "modulename": "clarena.cl_datasets.split_cifar100", "qualname": "SplitCIFAR100.std_original", "kind": "variable", "doc": "<p>The standard deviation values for normalisation.</p>\n", "annotation": ": tuple[float]", "default_value": "(0.3081,)"}, {"fullname": "clarena.cl_datasets.split_cifar100.SplitCIFAR100.prepare_data", "modulename": "clarena.cl_datasets.split_cifar100", "qualname": "SplitCIFAR100.prepare_data", "kind": "function", "doc": "<p>Download the original MNIST dataset if haven't.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.split_cifar100.SplitCIFAR100.train_and_val_dataset", "modulename": "clarena.cl_datasets.split_cifar100", "qualname": "SplitCIFAR100.train_and_val_dataset", "kind": "function", "doc": "<p>Get the training and validation dataset of task <code>self.task_id</code>.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The train and validation dataset of task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_datasets.split_cifar100.SplitCIFAR100.test_dataset", "modulename": "clarena.cl_datasets.split_cifar100", "qualname": "SplitCIFAR100.test_dataset", "kind": "function", "doc": "<p>Get the test dataset of task <code>self.task_id</code>.</p>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The test dataset of task <code>self.task_id</code>.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">Dataset</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_heads", "modulename": "clarena.cl_heads", "kind": "module", "doc": "<h1 id=\"continual-learning-heads\">Continual Learning Heads</h1>\n\n<p>This submodule provides the <strong>continual learning heads</strong> in CLArena. </p>\n\n<p>There are two types of heads in CLArena: <code>HeadsTIL</code> and <code>HeadsCIL</code>, corresponding to two CL paradigms respectively: Task-Incremental Learning (TIL) and Class-Incremental Learning (CIL). </p>\n\n<p>Please note that this is an API documantation. Please refer to the main documentation page for more information about the heads.</p>\n\n<ul>\n<li><strong>Configure your CL paradigm:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/</a></li>\n<li><strong>A beginners' guide to continual learning (Multi-head Classifier):</strong> <a href=\"https://pengxiang-wang.com/posts/continual-learning-beginners-guide#CL-classification\">https://pengxiang-wang.com/posts/continual-learning-beginners-guide#CL-classification</a></li>\n</ul>\n"}, {"fullname": "clarena.cl_heads.HeadsTIL", "modulename": "clarena.cl_heads", "qualname": "HeadsTIL", "kind": "class", "doc": "<p>The output heads for Task-Incremental Learning (TIL). Independent head assigned to each TIL task takes the output from backbone network and forwards it into logits for predicting classes of the task.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "clarena.cl_heads.HeadsTIL.__init__", "modulename": "clarena.cl_heads", "qualname": "HeadsTIL.__init__", "kind": "function", "doc": "<p>Initializes TIL heads object with no heads.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>input_dim</strong> (<code>int</code>): the input dimension of the heads. Must be equal to the <code>output_dim</code> of the connected backbone.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "clarena.cl_heads.HeadsTIL.heads", "modulename": "clarena.cl_heads", "qualname": "HeadsTIL.heads", "kind": "variable", "doc": "<p>The TIL output heads are stored independently in a ModuleDict (rather than dict just to make sure the parameters can be recorded in model summaries). Keys are task IDs and values are the corresponding <code>nn.Linear</code> heads.</p>\n", "annotation": ": torch.nn.modules.container.ModuleDict"}, {"fullname": "clarena.cl_heads.HeadsTIL.input_dim", "modulename": "clarena.cl_heads", "qualname": "HeadsTIL.input_dim", "kind": "variable", "doc": "<p>The input dimension of the heads. Used when creating new heads.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_heads.HeadsTIL.task_id", "modulename": "clarena.cl_heads", "qualname": "HeadsTIL.task_id", "kind": "variable", "doc": "<p>Task ID counter indicating which task is being processed. Self updated during the task loop.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_heads.HeadsTIL.setup_task_id", "modulename": "clarena.cl_heads", "qualname": "HeadsTIL.setup_task_id", "kind": "function", "doc": "<p>Create the output head when task <code>task_id</code> arrives if there's no. This must be done before <code>forward()</code> is called.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n<li><strong>num_classes_t</strong> (<code>int</code>): the number of classes in the task.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">num_classes_t</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_heads.HeadsTIL.forward", "modulename": "clarena.cl_heads", "qualname": "HeadsTIL.forward", "kind": "function", "doc": "<p>The forward pass for data from task <code>task_id</code>. A head is selected according to the task_id and the feature is passed through the head.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>feature</strong> (<code>Tensor</code>): the feature tensor from the backbone network.</li>\n<li><strong>task_id</strong> (<code>int</code>): the task ID where the data are from, which is provided by task-incremental setting.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The output logits tensor.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">feature</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_heads.HeadsCIL", "modulename": "clarena.cl_heads", "qualname": "HeadsCIL", "kind": "class", "doc": "<p>The output heads for Class-Incremental Learning (CIL). Head of all classes from CIL tasks takes the output from backbone network and forwards it into logits for predicting classes of all tasks.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "clarena.cl_heads.HeadsCIL.__init__", "modulename": "clarena.cl_heads", "qualname": "HeadsCIL.__init__", "kind": "function", "doc": "<p>Initializes a CIL heads object with no heads.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>input_dim</strong> (<code>int</code>): the input dimension of the heads. Must be equal to the <code>output_dim</code> of the connected backbone.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "clarena.cl_heads.HeadsCIL.heads", "modulename": "clarena.cl_heads", "qualname": "HeadsCIL.heads", "kind": "variable", "doc": "<p>The TIL output heads are stored independently in a ModuleDict (rather than dict just to make sure the parameters can be recorded in model summaries). Keys are task IDs and values are the corresponding <code>nn.Linear</code> heads.</p>\n", "annotation": ": torch.nn.modules.container.ModuleDict"}, {"fullname": "clarena.cl_heads.HeadsCIL.input_dim", "modulename": "clarena.cl_heads", "qualname": "HeadsCIL.input_dim", "kind": "variable", "doc": "<p>The input dimension of the heads. Used when creating new heads.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_heads.HeadsCIL.task_id", "modulename": "clarena.cl_heads", "qualname": "HeadsCIL.task_id", "kind": "variable", "doc": "<p>Task ID counter indicating which task is being processed. Self updated during the task loop.</p>\n", "annotation": ": int"}, {"fullname": "clarena.cl_heads.HeadsCIL.setup_task_id", "modulename": "clarena.cl_heads", "qualname": "HeadsCIL.setup_task_id", "kind": "function", "doc": "<p>Create the output head when task <code>task_id</code> arrives if there's no. This must be done before <code>forward()</code> is called.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>task_id</strong> (<code>int</code>): the target task ID.</li>\n<li><strong>num_classes_t</strong> (<code>int</code>): the number of classes in the task.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">num_classes_t</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.cl_heads.HeadsCIL.forward", "modulename": "clarena.cl_heads", "qualname": "HeadsCIL.forward", "kind": "function", "doc": "<p>The forward pass for data. The information of which <code>task_id</code> the data are from is not provided. The head for all classes is selected and the feature is passed.</p>\n\n<p><strong>Args:</strong></p>\n\n<ul>\n<li><strong>feature</strong> (<code>Tensor</code>): the feature tensor from the backbone network.</li>\n<li><strong>task_id</strong> (<code>int</code> or <code>None</code>): the task ID where the data are from. In CIL, it is just a placeholder for API consistence with the TIL heads but never used. Best practices are not to provide this argument and leave it as the default value.</li>\n</ul>\n\n<p><strong>Returns:</strong></p>\n\n<ul>\n<li>The output logits tensor.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">feature</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"n\">task_id</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "clarena.optimizers", "modulename": "clarena.optimizers", "kind": "module", "doc": "<h1 id=\"optimizers-for-continual-learning\">Optimizers for Continual Learning</h1>\n\n<p>This submodule provides <strong>optimizers for continual learning</strong> that can be used in CLArena. </p>\n\n<p>Please note that this is an API documantation. Please refer to the main documentation page for more information about the optimizers and how to use and customize them:</p>\n\n<ul>\n<li><strong>Configure your optimizer:</strong> <a href=\"https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/optimizer\">https://pengxiang-wang.com/projects/continual-learning-arena/docs/configure-your-experiments/optimizer</a></li>\n</ul>\n"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();