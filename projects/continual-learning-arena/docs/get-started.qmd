---
title: Get Started
number-sections: true
---

This is a quick guide to set up CLArena, run a continual learning experiment and check the results.


# Install

CLArena is a Python package that is not yet available on PyPI. For now, please install it manually in your Python environment by following the instructions below:

```bash
git clone https://github.com/pengxiang-wang/continual-learning-arena

# [OPTIONAL] create conda environment
conda create -n your-env-name python=3.12
conda activate your-env-name

pip install ./continual-learning-arena
```


# Run Default Experiment

To run the default experiment, download and extract the example config files:

::: { .text-center}
[Download Example Configs (zip)](../resources/example_configs.zip){ .btn .btn-success role="button"}
[Example Configs (GitHub)](https://github.com/pengxiang-wang/continual-learning-research/tree/main/example_configs/){ .btn .btn-info role="button"}
:::

Executed the command `cltrain` with specifying the path of extracted example configs. This will train the continual learning model with the default configuration.

```bash
cltrain example --config-dir <path/to/example_configs>
```

<details>

  <summary>Default Configuration</summary>

- CL Dataset: [TIL (task-incremental learning)](../../../posts/continual-learning-beginners-guide.qmd#TIL), [Permuted MNIST](../../../posts/continual-learning-beginners-guide.qmd#CL-dataset), [classification](../../../posts/continual-learning-beginners-guide.qmd#CL-classification), 10 tasks
- Backbone Network: MLP (Fully-Connected Network)
- CL Algorithm: [Finetuning](../../../posts/continual-learning-beginners-guide.qmd#CL-baselines), simply initialising from the last task
- Training: 5 epochs for each task, batch size 64, on your local CPU

</details>

# Check the Results

After running the command, a directory will be created under `outputs/example/`containing all the information and outputs from the experiment, where "example" is the experiment name defined in the config. The folder will be named after the execution time (multiple runs will be stored separately if the command is executed more than once).

You can check the results produced so far in this directory at any point during the experiment. The results can include:

- `acc.csv` and `loss_cls.csv`: the performance matrix and average performance. If you are not familiar with metrics continual learning, feel free to get some knowledge from my [CL beginner's guide](../../../posts/continual-learning-beginners-guide.qmd#CL-metrics);
- Checkpoints of each task in `checkpoints/` folders in `lightning_logs/`;
- A full copy of this experiment config in `.hydra/` for your future reference;
- The related files for some loggers like Tensorboard;
- ...

You can configure the output files by adjusting the configs that control them to suit your needs.


