---
title: "Continual Learning + Machine Unlearning"
author:
    - Pengxiang Wang
institute:
    - Peking University, School of Mathematical Sciences
    - University of Bristol, School of Engineering Mathematics and Technology
date: 2024-10-28
navigation: horizontal
aspectratio: 169
header-includes: |
  \setbeamertemplate{footline}[frame number]
  \titlegraphic{
    \centering
    \includegraphics[height=0.8cm]{../assets/pku-logo.png} \hspace{0.5cm}
    \includegraphics[height=0.8cm]{../assets/uob-logo.png}
  }
section-titles: true
theme: default
format:
    beamer:
        toc: false
        incremental: false
toc: true
image: assets/CLPU.png
categories: [research]
---

# Machine Unlearning

## Machine Unlearning Motivation

What is **machine unlearning**:

> **Machine unlearning** is the process of deliberately removing specific data from a machine learning model to ensure that the removed data no longer influences the model’s predictions -- an undo option of machine learning process.


Data Deletion:

- Traditionally: delete from databases
- AI: delete both from back-end databases and from trained models

Application Movitation:

- **Privacy**: 
  - Regulations: GDPR, CCPA, etc. when the user withdraw the consent, "the right to be forgotten"
  - Delete the requested data by users
- **Security**: 
  - Adversarial attacks are possible to extract private information from the trained model. E.g., model inversion attacks, membership inference attacks, etc.
  - Delete the adversial data
- **Data Quality**: 
- Delete unwanted data, e.g., outdated data, noisy data, biased data, etc.


## Machine Unlearning Framework

![Machine Unlearning Framework](assets/machine-unlearning-framework.png)


## Formal Definition

D = Dr+ Df

Df: forget set

Assumptions: 

- The unlearning data are not big. Practically considering, also Otherwise, it is easier to do retraining.

## Retraining

The problem makes unlearning difficult:

- Neural networks parameters do not tend to show any clear connection to the training data. AI models have to be considered as a whole.
- Stochasticity and Incrementality of training
- 这种整体性很容易导致unlearning过头，catastrophic unlearning, reduce performance


**Retraining:**

- Delete target data and re-train the model with the rest of data from scratch
- A naive way, but not always feasible
- Achieves upper bound 


The problem of retraining:
- Doesn't worth, computation cost
- Not always having aceess to all training data


## Methodology

Scenarios
- Data Deletion
- Class Removal


- Model-Agnostic or Model-Intrinsic
- Data-Driven Approaches, most model-agnostic

## Method: SISA

Data Partitioning (Efficient Retraining)

SISA (Sharded, Isolated, Sliced, Aggregated), 2021:

- Isolate: Isolate network and slice data into shards
- build up correspondance bewteen divided network and data
- Retraining the corresponding network of the data shard to be forgotten

Fractioning the retraining into smaller units

## Method: SISA

![SISA](assets/SISA.png)

